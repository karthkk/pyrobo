{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sys.path.append('/home/karthik/code/pyrobo/network_models/')\n",
    "from multicam_net import PurchasePredNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images_folder = '/data/robotics/pick_episodes/'\n",
    "training_data = [os.path.join(images_folder,x) for x in os.listdir(images_folder)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_image(feature, name):\n",
    "    image = feature[name].bytes_list\n",
    "    arr = np.fromstring(image.value[0],dtype=np.uint8).reshape((480, 640, 3))\n",
    "    return cv2.resize(arr, (224, 224))\n",
    "\n",
    "\n",
    "def motor_2_label(motor, direction):\n",
    "    return 2*motor+(direction+1)/2\n",
    "\n",
    "def get_total_samples(training_data):\n",
    "    total_samples = 0\n",
    "    train_inp = np.zeros((total_samples, ))\n",
    "    example = tf.train.Example()\n",
    "    for fl in training_data:\n",
    "        riter = tf.python_io.tf_record_iterator(fl)\n",
    "        for dat in riter:\n",
    "            total_samples+=1\n",
    "    return total_samples\n",
    "\n",
    "total_samples = get_total_samples(training_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_inp = np.zeros((2, total_samples, 224, 224, 3), dtype=np.uint8)\n",
    "labels = np.zeros((total_samples,), dtype=np.int32)\n",
    "current_sample = 0\n",
    "example = tf.train.Example()\n",
    "for fl in training_data:\n",
    "    riter = tf.python_io.tf_record_iterator(fl)\n",
    "    for dat in riter:\n",
    "        example.ParseFromString(dat)\n",
    "        feature = example.features.feature\n",
    "        direction = feature['direction'].int64_list.value[0]\n",
    "        motor = feature['motor'].int64_list.value[0]\n",
    "        left_image = get_image(feature, 'left_image')\n",
    "        right_image = get_image(feature, 'right_image')\n",
    "        labels[current_sample] = motor_2_label(motor, direction) \n",
    "        train_inp[0, current_sample, ...] = left_image\n",
    "        train_inp[1, current_sample, ...] = right_image\n",
    "        current_sample+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net = PurchasePredNet()\n",
    "sess = tf.Session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels_pl = tf.placeholder(shape=(None,), dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=net.layers['out'], labels=labels_pl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdadeltaOptimizer(0.001)\n",
    "train = optimizer.minimize(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accuracy = tf.metrics.accuracy (labels=labels_pl, predictions=tf.argmax(net.layers['out'], axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())\n",
    "net.load('/data/image/models/VGG_imagenet.npy', sess, ignore_missing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for step in range(50000):\n",
    "    idxes = np.random.randint(0, total_samples-1, size=BATCH_SIZE)\n",
    "    left_im = train_inp[0, idxes, ...]\n",
    "    right_im = train_inp[1, idxes, ...]\n",
    "    labels_x = labels[idxes]\n",
    "    [_, lv] = sess.run([train, loss], {labels_pl: labels_x, \n",
    "                                                    net.left_img:left_im,\n",
    "                                                    net.right_img: right_im})\n",
    "    if step%1000 == 0:\n",
    "        print(\"Step %d, Loss %f\"%(step, lv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "saver.save(sess, '/data/robotics/models/pick_episodes/25000_iters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = np.load('/data/image/models/VGG_imagenet.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dct = data.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dct['conv5_3']['weights'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "512*3*3*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net.layers['merged'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "28*14*512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
