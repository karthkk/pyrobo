{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import collections\n",
    "\n",
    "\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from tftools import data\n",
    "import sys\n",
    "import os\n",
    "episode_model_save_location = '/data/robotics/pick_episodes/models'\n",
    "episode_data_save_location = '/data/robotics/pick_episodes/data'\n",
    "pyrobo_path = '/home/karthik/code/pyrobo/'\n",
    "sys.path.append(os.path.join(pyrobo_path, 'network_models'))\n",
    "sys.path.insert(0, '/home/karthik/code/pytools/src/')\n",
    "\n",
    "from tftools import network as nw\n",
    "import multicam_net\n",
    "import trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def load_all_training_data(train_data_location):\n",
    "    train_files = [os.path.join(train_data_location, f) for f in os.listdir(train_data_location)\n",
    "                   if f.endswith('.tfrecords')]\n",
    "    img_cnt = 0\n",
    "    for train_fl in train_files:\n",
    "        img_cnt += data.TFDataReader(train_fl).count()\n",
    "    train_inp = np.zeros([2, img_cnt, 224, 224, 3], dtype=np.uint8)\n",
    "    train_labels = np.zeros([img_cnt, ], dtype=np.int32)\n",
    "    train_states = np.zeros([img_cnt, 6], dtype=np.float32)\n",
    "    train_values = np.zeros([img_cnt, ], dtype=np.float32)\n",
    "    end_states = np.zeros([img_cnt, ], dtype=np.int32)\n",
    "    idx = 0\n",
    "    for train_fl in train_files:\n",
    "        reader = data.TFDataReader(train_fl)\n",
    "        fds = reader.readall(([\"left_image\", data.IMG_TYP],\n",
    "                              [\"right_image\", data.IMG_TYP],\n",
    "                              ['motor', data.INT_TYP],\n",
    "                              ['direction', data.INT_TYP],\n",
    "                              ['motor_state', data.FLT_TYP]))\n",
    "        value_idx = 0.\n",
    "        value_count = len(fds)\n",
    "        for fd in fds:\n",
    "            train_inp[0, idx, ...] = multicam_net.resize_to_model(fd['left_image'])\n",
    "            train_inp[1, idx, ...] = multicam_net.resize_to_model(fd['right_image'])\n",
    "            motor = int(fd['motor'][0])\n",
    "            direction = int(fd['direction'][0])\n",
    "            train_states[idx, :] = np.array(fd['motor_state'])\n",
    "            label = trainer.motor_2_label(motor, direction)\n",
    "            train_values[idx] = value_idx/value_count\n",
    "            train_labels[idx] = label\n",
    "            idx += 1\n",
    "            value_idx+=1\n",
    "        end_states[idx-1] = 1\n",
    "\n",
    "    return ((train_inp, train_labels, train_states, train_values, end_states), img_cnt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "((train_inp, train_labels, train_states, train_values, end_states), img_cnt) = load_all_training_data(episode_data_save_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class MultiImageAutEnModel(nw.Network):\n",
    "    def __init__(self):\n",
    "        self.left_img = tf.placeholder(tf.float32, shape=[None, 224, 224, 3])\n",
    "        self.right_img = tf.placeholder(tf.float32, shape=[None, 224, 224, 3])\n",
    "        self.img = tf.concat(values=[self.left_img, \n",
    "                                     self.right_img], axis=3)\n",
    "        self.layers = dict({'img':self.img})\n",
    "        self.trainable = True\n",
    "        self.initializer =  tf.contrib.layers.xavier_initializer(uniform=True, seed=None, dtype=tf.float32)\n",
    "        self.setup()        \n",
    "        \n",
    "    def setup(self):\n",
    "        (self.feed('img')\n",
    "             .conv(7, 7, 64*2, 2, 2,  name='conv1_7x7_s2', trainable=False, group=2)\n",
    "             .max_pool(3, 3, 2, 2,  name='pool1_3x3_s2')\n",
    "             .lrn(2, 2e-05, 0.75,   name='pool1_norm1')\n",
    "             .conv(1, 1, 64*2, 1, 1,  name='conv2_3x3_reduce', trainable=False, group=2)\n",
    "             .conv(3, 3, 192*2, 1, 1, name='conv2_3x3', trainable=False, group=2)\n",
    "             .lrn(2, 2e-05, 0.75,   name='conv2_norm2')\n",
    "             .max_pool(3, 3, 2, 2,  name='pool2_3x3_s2'))\n",
    "        \n",
    "        (self.feed('pool2_3x3_s2')\n",
    "             .conv(1, 1, 64*2, 1, 1, name='inception_3a_3x3_reduce', group=2)\n",
    "             .conv(3, 3, 32*2, 1, 1, name='inception_3a_3x3', group=2) \n",
    "             .conv(3, 3, 32, 1, 1, name='inception_3b_3x3')) \n",
    "        \n",
    "        (self.feed('inception_3b_3x3')\n",
    "            .fc(4096, name=\"fc1\")\n",
    "            .fc(512, name=\"fc3\")\n",
    "            .fc(128, name=\"bn\"))\n",
    "\n",
    "        (self.feed('bn')\n",
    "            .fc(128, name='bc1')\n",
    "            .fc(384, name='bc2')\n",
    "            .fc(384*2, name='out'))\n",
    "        \n",
    "        (self.feed(\"conv2_3x3\")\n",
    "        .spatial_softmax(name='ss'))\n",
    "        \n",
    "        (self.feed('bn')\n",
    "            .fc(128, name='val_1')\n",
    "            .fc(16, name='val_2')\n",
    "            .fc(1, name='val_out'))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "net = MultiImageAutEnModel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "lr = tf.placeholder(dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.square(net.layers['ss'] - net.layers['out']))\n",
    "optimizer = tf.train.GradientDescentOptimizer(lr)\n",
    "train_op = optimizer.minimize(loss)\n",
    "\n",
    "val_optimizer = tf.train.RMSPropOptimizer(lr)\n",
    "\n",
    "values = tf.placeholder(shape=(None,), dtype=tf.float32)\n",
    "value_loss = tf.reduce_mean(tf.square(values  - net.layers['val_out']))\n",
    "value_train = val_optimizer.minimize(value_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "net.load('/data/image/models/googlenet.npy', sess, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "last_100_1 = collections.deque(100*[100], 100)\n",
    "last_100_2 = collections.deque(100*[100], 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "LR = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tr = tqdm.tnrange(1000)\n",
    "for step in tr:\n",
    "    idxes = np.random.randint(0, img_cnt, size=16)\n",
    "    left_im = train_inp[0, idxes, ...]\n",
    "    right_im = train_inp[1, idxes, ...]\n",
    "    batch_data = {\n",
    "                    net.left_img: left_im,\n",
    "                    net.right_img: right_im,\n",
    "                values: train_values[idxes],\n",
    "                lr: LR}\n",
    "    [_, lv1] = sess.run([value_train, value_loss], batch_data)\n",
    "    batch_data = {\n",
    "                net.left_img: left_im,\n",
    "                net.right_img: right_im,\n",
    "                lr: LR}\n",
    "    [_, lv2] = sess.run([train_op, loss], batch_data)\n",
    "\n",
    "    last_100_1.append(lv1)\n",
    "#     last_100_2.append(lv2)\n",
    "    tr.set_postfix(loss1=np.mean(last_100_1), loss2=np.mean(last_100_2))\n",
    "b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "net.initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tf.contrib.layers.xavier_initializer(uniform=True, seed=None, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "tot = 0\n",
    "bel0pt1 = 0\n",
    "for l in open('/home/karthik/code/images/simul_learning_test/final_loss_single').readlines():\n",
    "    v = eval(l.strip())\n",
    "    cnt+=1\n",
    "    tot+=v[0]\n",
    "    if v[0] < 0.1:\n",
    "        bel0pt1+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "net.layers['conv1_7x7_s2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import vpnotebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from vpython import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "box()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
